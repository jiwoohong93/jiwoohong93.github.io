---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

# About Me

<span class='anchor' id='about-me'></span>
I am a Ph.D. candidate at the <strong>U-AIM (Artificial Intelligence & Machine Learning)</strong> Lab, KAIST (Korea Advanced Institute of Science and Technology), advised by Prof. [Chang D. Yoo](http://sanctusfactory.com/family.php).

My primary research interests lie in the application of <strong>generative models for computer vision</strong>, with a recent focus on <strong>virtual try-on</strong> and multi-modal image/video editing.

If you want to know more about me, please refer to my
<!-- CV Download Button -->
<a href="images/cv.pdf" target="_blank" class="button is-link is-light is-medium mt-3">
  CV.
</a>

<!-- 
My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# News
- *2025.02*: &nbsp; One paper accepted to CVPR 2025.
- *2024.10*: &nbsp; 1st place winner of the '2nd Seoul National University Bundang Hospital (SNUBH) Datathon'.
- *2024.07*: &nbsp; Two papers accepted to ECCV 2024.


# Publications 
[*] equal contribution


<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPR 2025</div><img src='images/cvpr2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C8**] [**ITA-MDT:Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On**](https://arxiv.org/pdf/2503.20418)

<span style="color:royalblue">**Ji Woo Hong** </span>, Tri Ton, Trung X. Pham, Gwanhyeong Koo, Sunjae Yoon, Chang D. Yoo

Computer Vision and Pattern Recognition (**CVPR**) 2025

[[Project Page]](https://jiwoohong93.github.io/ita-mdt/)

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2024</div><img src='images/eccv2024_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">


[**C7**] [**Dilutional Noise Initialization for Dilution Video Editing**](https://arxiv.org/abs/2409.13037v1)

Sunjae Yoon, Gwanhyeong Koo, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2024

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2024</div><img src='images/eccv2024_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">


[**C6**] [**FlexiEdit: Frequency-Aware Latent Refinement for Enhanced Non-Rigid Editing**](https://arxiv.org/abs/2407.17850)

Gwanhyeong Koo, Sunjae Yoon, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2024

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPRW 2024</div><img src='images/cvprw2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">


[**C5**] [**Zero-shot Dual-Path Integration Framework for Open-Vocabulary 3D Instance Segmentation**](https://arxiv.org/pdf/2408.08591)

Gwanhyeong Koo, Sunjae Yoon, Ji Woo Hong and Chang D. Yoo
Tri Ton*, <span style="color:royalblue">**Ji Woo Hong** </span>*, SooHwan Eom, Jun Yeop Shim, Junyeong Kim, and Chang D. Yoo. 
Computer Vision and Pattern Recognition Workshop (OpenSUN3D: 2nd Workshop on Open-Vocabulary 3D Scene Understanding) (**CVPRW**) 2024 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2023</div><img src='images/icassp2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C4**] [**Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval**](https://ieeexplore.ieee.org/document/10095182)

Sunjae Yoon, <span style="color:royalblue">**Ji Woo Hong** </span>, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, <span style="color:#8B0000">**Oral**</span>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2022</div><img src='images/eccv2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C3**] [**Selective Query-guided Debiasing for Video Corpus Moment Retrieval**](https://arxiv.org/pdf/2210.08714.pdf) 

[[code]](https://github.com/dbstjswo505/SQuiDNet)

Sunjae Yoon, <span style="color:royalblue">**Ji Woo Hong** </span>, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2022

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2022</div><img src='images/icassp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C2**] [**SEMANTIC ASSOCIATION NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9747523) 

Dahyun Kim*, Sunjae Yoon*, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022. <span style="color:#8B0000">**Oral**</span>

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div class="badge">ICIP 2021</div><img src='images/icip2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C1**] [**WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9506218) 

[[code]](https://github.com/dbstjswo505/WMRN)

Sunjae Yoon*, Dahyun Kim*, <span style="color:royalblue">**Ji Woo Hong** </span> , Junyeong Kim, Kookhoi Kim and Chang D. Yoo

International Conference on Image Processing (**ICIP**), 2021

</div>
</div>



[**J5**] [**Causal Localization Network for Radar Human Localization with micro-Doppler signature**](https://ieeexplore.ieee.org/document/10387441)

Sunjae Yoon Gwanhyeong Koo, Jun Yeop Shim, Soohwan Eom, <span style="color:royalblue">**Ji Woo Hong** </span>, Chang D. Yoo

[[code]](https://github.com/dbstjswo505/CLNet)

IEEE Access, 2024
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J4**] [**Self-Supervised Visual Representation Learning via Residual Momentum**](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10287941)

Trung X. Pham, Axi Niu, Zhang Kang, Tee Joshua Tian Jin, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo. 

IEEE Access 2023.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J3**] [**Joint Path Alignment Framework for 3D Human Pose and Shape Estimation from Video**](https://ieeexplore.ieee.org/document/10109716)

<span style="color:royalblue">**Ji Woo Hong** </span>, Sunjae Yoon, Junyeong Kim, and Chang D. Yoo  

IEEE Access, 2023

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J2**] [**CE-BART: Cause-and-Effect BART for Visual Comonsense Generation**](https://www.mdpi.com/1424-8220/22/23/9399)

Junyeong Kim, <span style="color:royalblue">**Ji Woo Hong** </span>, Sunjae Yoon, and Chang D. Yoo  

MDPI Sensors, 2022

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J1**] [**Dual-Scale Doppler Attention for Human Identification**](https://www.mdpi.com/1424-8220/22/17/6363) 

[[code]](https://github.com/dbstjswo505/DSDA)

Sunjae Yoon, Dahyun Kim, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

MDPI Sensors, 2022

</div>
</div>



# Awards
- *2024.10* 1st place winner of the '2nd Seoul National University Bundang Hospital (SNUBH) Datathon.'
- *2023.11* Winner of Best Paper Award, Winter Conference of Korean Artificial Intelligence Association (KAIA). 

# Educations
Korea Advanced Institute of Science and Technology (KAIST)
- *Aug. 2022 - now*: __M.S.__ in Electrical Engineering (Artificial Intelligence & Machine Learning).
&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- *Graduation: Aug. 2022*: __M.S.__ in Robotics Program (Artificial Intelligence & Machine Learning).
&emsp;&emsp;&emsp;Thesis: "Temporal Procrustes Alignment Framework for 3D Human Pose and Shape Estimation from Video"
&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

Michigan State University (MSU)
- *Graduation: May 2019*: __B.S.__ in Mechanical Engineering, minor in Computer Science.

# Projects
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.

- *Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics (Operator)*
&emsp;&emsp;&emsp;IITP grant funded by the Korea Government (MSIT) Mar. 2022 - present
- *Development of Causal AI through Video Understanding and Reinforcement Learning, and Its Applications to Real Environments (Supporter)*
&emsp;&emsp;&emsp;IITP grant funded by the Korea Government (MSIT) Mar. 2021 - present
- *Development of framework for analyzing, detecting, mitigating of bias in AI model and training data (Operator)*
&emsp;&emsp;&emsp;IITP grant funded by the Korea Government (MSIT) Jan. 2021 – Dec. 2022


# Reviewer
- *Conference on Computer Vision and Pattern Recognition (CVPR)*: 2025
- *International Conference on Computer Vision (ICCV)*: 2025
- *European Conference on Computer Vision (ECCV)*: 2024
- *International Conference on Acoustics, Speech & Signal Processing (ICASSP)*: 2023, 2024

# Teaching Assistant
- *Statistical Learning Theory*: 2024 Spring, 2024 Fall
- *Introduction to Machine Learning*: 2023 Fall 
- *Signals and Systems*: 2022 Fall, 2023 Spring
- *Seongnam-KAIST Next Generation ICT Research Center. EE Co-op+ Joint Research Program*: 2023 Fall, 2024 Spring, 2024 Fall

<!-- # Internships
- *2025.7 - 2025.12*, Microsoft Research Asia (MSRA), Shanghai.
&emsp;&emsp;&emsp;Mentor: Chong Luo -->
