---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}



# About Me

<span class='anchor' id='about-me'></span>
I am a Ph.D. candidate at the <strong>U-AIM (Artificial Intelligence & Machine Learning)</strong> Lab, KAIST (Korea Advanced Institute of Science and Technology), advised by Prof. [Chang D. Yoo](http://sanctusfactory.com/family.php).

My primary research interests lie in the application of <strong>generative models for computer vision</strong>, with a recent focus on <strong>virtual try-on</strong> and multi-modal image/video editing.

If you want to know more about me, please refer to my
<!-- CV Download Button -->
<a href="images/cv.pdf" target="_blank" class="button is-link is-light is-medium mt-3">
  CV.
</a>

<!-- 
My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# News

<span class='anchor' id='news'></span>

- *Feb. 2025*: &nbsp; One paper accepted to CVPR 2025.
- *Oct. 2024*: &nbsp; 1st place winner of the '2nd Seoul National University Bundang Hospital (SNUBH) Datathon'.
- *Jun. 2024*: &nbsp; Two papers accepted to ECCV 2024.


# Publications 

<span class='anchor' id='publications'></span>

[*] equal contribution


<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPR 2025</div><img src='images/cvpr2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C8**] [**ITA-MDT:Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On**](https://arxiv.org/pdf/2503.20418)

<span style="color:royalblue">**Ji Woo Hong** </span>, Tri Ton, Trung X. Pham, Gwanhyeong Koo, Sunjae Yoon, Chang D. Yoo

*Computer Vision and Pattern Recognition (**CVPR**), 2025*

[[Project Page]](https://jiwoohong93.github.io/ita-mdt/)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2024</div><img src='images/eccv2024_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">


[**C7**] [**Dilutional Noise Initialization for Dilution Video Editing**](https://arxiv.org/abs/2409.13037v1)

Sunjae Yoon, Gwanhyeong Koo, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

*European Conference on Computer Vision (**ECCV**), 2024*

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2024</div><img src='images/eccv2024_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">


[**C6**] [**FlexiEdit: Frequency-Aware Latent Refinement for Enhanced Non-Rigid Editing**](https://arxiv.org/abs/2407.17850)

Gwanhyeong Koo, Sunjae Yoon, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

*European Conference on Computer Vision (**ECCV**), 2024*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPRW 2024</div><img src='images/cvprw2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C5**] [**Zero-shot Dual-Path Integration Framework for Open-Vocabulary 3D Instance Segmentation**](https://arxiv.org/pdf/2408.08591)

Tri Ton *, <span style="color:royalblue">**Ji Woo Hong** </span> *, SooHwan Eom, Jun Yeop Shim, Junyeong Kim, and Chang D. Yoo. 

*Computer Vision and Pattern Recognition Workshop (OpenSUN3D: 2nd Workshop on Open-Vocabulary 3D Scene Understanding) (**CVPRW**), 2024*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2023</div><img src='images/icassp2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C4**] [**Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval**](https://ieeexplore.ieee.org/document/10095182)

Sunjae Yoon, <span style="color:royalblue">**Ji Woo Hong** </span>, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, and Chang D. Yoo

*The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, <span style="color:#8B0000">**Oral**</span>*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2022</div><img src='images/eccv2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C3**] [**Selective Query-guided Debiasing for Video Corpus Moment Retrieval**](https://arxiv.org/pdf/2210.08714.pdf) 

[[code]](https://github.com/dbstjswo505/SQuiDNet)

Sunjae Yoon, <span style="color:royalblue">**Ji Woo Hong** </span>, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo

*European Conference on Computer Vision (**ECCV**), 2022*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2022</div><img src='images/icassp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C2**] [**SEMANTIC ASSOCIATION NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9747523) 

Dahyun Kim *, Sunjae Yoon *, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

*The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022. <span style="color:#8B0000">**Oral**</span>*

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div class="badge">ICIP 2021</div><img src='images/icip2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C1**] [**WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9506218) 

[[code]](https://github.com/dbstjswo505/WMRN)

Sunjae Yoon *, Dahyun Kim *, <span style="color:royalblue">**Ji Woo Hong** </span> , Junyeong Kim, Kookhoi Kim and Chang D. Yoo

*International Conference on Image Processing (**ICIP**), 2021*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2024</div><img src='images/access2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J5**] [**Causal Localization Network for Radar Human Localization with micro-Doppler signature**](https://ieeexplore.ieee.org/document/10387441)

Sunjae Yoon Gwanhyeong Koo, Jun Yeop Shim, Soohwan Eom, <span style="color:royalblue">**Ji Woo Hong** </span>, Chang D. Yoo

*IEEE Access, 2024*

[[code]](https://github.com/dbstjswo505/CLNet)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J4**] [**Self-Supervised Visual Representation Learning via Residual Momentum**](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10287941)

Trung X. Pham, Axi Niu, Zhang Kang, Tee Joshua Tian Jin, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo. 

*IEEE Access, 2023*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J3**] [**Joint Path Alignment Framework for 3D Human Pose and Shape Estimation from Video**](https://ieeexplore.ieee.org/document/10109716)

<span style="color:royalblue">**Ji Woo Hong** </span>, Sunjae Yoon, Junyeong Kim, and Chang D. Yoo  

*IEEE Access, 2023*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J2**] [**CE-BART: Cause-and-Effect BART for Visual Comonsense Generation**](https://www.mdpi.com/1424-8220/22/23/9399)

Junyeong Kim, <span style="color:royalblue">**Ji Woo Hong** </span>, Sunjae Yoon, and Chang D. Yoo  

*MDPI Sensors, 2022*

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J1**] [**Dual-Scale Doppler Attention for Human Identification**](https://www.mdpi.com/1424-8220/22/17/6363) 

[[code]](https://github.com/dbstjswo505/DSDA)

Sunjae Yoon, Dahyun Kim, <span style="color:royalblue">**Ji Woo Hong** </span>, and Chang D. Yoo

*MDPI Sensors, 2022*

</div>
</div>



# Awards

<span class='anchor' id='awards'></span>

- *Oct. 2024* 1st place winner of the '2nd Seoul National University Bundang Hospital (SNUBH) Datathon.'
- *Nov. 2023* Winner of Best Paper Award, Winter Conference of Korean Artificial Intelligence Association (KAIA). 

# Educations

<span class='anchor' id='educations'></span

__Korea Advanced Institute of Science and Technology (KAIST)__

- *Aug. 2022 - now*: __Ph.D.__ in Electrical Engineering (Artificial Intelligence & Machine Learning).

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- *Graduation: Aug. 2022*: __M.S.__ in Robotics Program (Artificial Intelligence & Machine Learning).

&emsp;&emsp;&emsp;Thesis: "Temporal Procrustes Alignment Framework for 3D Human Pose and Shape Estimation from Video"

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

__Michigan State University (MSU)__

- *Graduation: May 2019*: __B.S.__ in Mechanical Engineering, minor in Computer Science.


# Projects

<span class='anchor' id='projects'></span>

- __Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics (Operator)__

&emsp;&emsp;&emsp;IITP grant funded by the Korea Government (MSIT) *Mar. 2022 - present*


- __Development of Causal AI through Video Understanding and Reinforcement Learning, and Its Applications to Real Environments (Supporter)__

&emsp;&emsp;&emsp;IITP grant funded by the Korea Government (MSIT) *Mar. 2021 - present*


- __Development of framework for analyzing, detecting, mitigating of bias in AI model and training data (Operator)__

&emsp;&emsp;&emsp; IITP grant funded by the Korea Government (MSIT) *Jan. 2021 â€“ Dec. 2022*


# Reviewer

<span class='anchor' id='reviewer'></span>

- __Conference on Computer Vision and Pattern Recognition (CVPR)__: *2025*
- __International Conference on Computer Vision (ICCV)__: *2025*
- __European Conference on Computer Vision (ECCV)__: *2024*
- __International Conference on Acoustics, Speech & Signal Processing (ICASSP)__: *2023, 2024*

# Teaching Assistant

<span class='anchor' id='teaching-assistant'></span>

- __Statistical Learning Theory__: *2024 Spring, 2024 Fall*
- __Introduction to Machine Learning__: *2023 Fall*
- __Signals and Systems__: *2022 Fall, 2023 Spring*
- __Seongnam-KAIST Next Generation ICT Research Center. EE Co-op+ Joint Research Program__: *2023 Fall, 2024 Spring, 2024 Fall*

<!-- # Internships
- *2025.7 - 2025.12*, Microsoft Research Asia (MSRA), Shanghai.
&emsp;&emsp;&emsp;Mentor: Chong Luo -->
